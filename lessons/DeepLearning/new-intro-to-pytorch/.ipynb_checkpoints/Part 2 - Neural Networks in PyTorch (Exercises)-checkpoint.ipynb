{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch\n",
    "\n",
    "Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module `nn` that provides a nice way to efficiently build large neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image. Here we'll use the MNIST dataset which consists of greyscale handwritten digits. Each image is 28x28 pixels, you can see a sample below\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Our goal is to build a neural network that can take one of these images and predict the digit in the image.\n",
    "\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/mohammad/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9789440/9912422 [00:14<00:00, 2518805.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohammad/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/mohammad/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 91498.85it/s]\u001b[A\n",
      "32768it [00:00, 60615.86it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohammad/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/mohammad/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:00<00:19, 85391.37it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:00<00:15, 102106.67it/s]\u001b[A\n",
      "  5%|▍         | 81920/1648877 [00:00<00:12, 124361.29it/s]\u001b[A\n",
      " 11%|█         | 180224/1648877 [00:01<00:09, 162793.13it/s]\u001b[A\n",
      " 22%|██▏       | 368640/1648877 [00:01<00:05, 219509.89it/s]\u001b[A\n",
      " 37%|███▋      | 614400/1648877 [00:01<00:03, 295092.93it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:01<00:01, 391119.98it/s]\u001b[A\n",
      " 69%|██████▉   | 1138688/1648877 [00:01<00:01, 507526.57it/s]\u001b[A\n",
      " 86%|████████▋ | 1425408/1648877 [00:01<00:00, 642537.24it/s]\u001b[A\n",
      "1654784it [00:01, 885461.19it/s]                             \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohammad/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/mohammad/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\n",
      "8192it [00:00, 26122.80it/s]            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohammad/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9920512it [00:30, 2518805.81it/s]                             "
     ]
    }
   ],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. Later, we'll use this to loop through the dataset for training, like\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "You'll notice I created the `trainloader` with a batch size of 64, and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a *batch*. And `shuffle=True` tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size `(64, 1, 28, 28)`. So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what one of the images looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to build a simple network for this dataset using weight matrices and matrix multiplications. Then, we'll see how to do it using PyTorch's `nn` module which provides a much more convenient and powerful method for defining network architectures.\n",
    "\n",
    "The networks you've seen so far are called *fully-connected* or *dense* networks. Each unit in one layer is connected to each unit in the next layer. In fully-connected networks, the input to each layer must be a one-dimensional vector (which can be stacked into a 2D tensor as a batch of multiple examples). However, our images are 28x28 2D tensors, so we need to convert them into 1D vectors. Thinking about sizes, we need to convert the batch of images with shape `(64, 1, 28, 28)` to a have a shape of `(64, 784)`, 784 is 28 times 28. This is typically called *flattening*, we flattened the 2D images into 1D vectors.\n",
    "\n",
    "Previously you built a network with one output unit. Here we need 10 output units, one for each digit. We want our network to predict the digit shown in an image, so what we'll do is calculate probabilities that the image is of any one digit or class. This ends up being a discrete probability distribution over the classes (digits) that tells us the most likely class for the image. That means we need 10 output units for the 10 classes (digits). We'll see how to convert the network output into a probability distribution next.\n",
    "\n",
    "> **Exercise:** Flatten the batch of images `images`. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.3812e+00, -5.7242e+00,  7.5836e+00,  7.9430e+00,  1.2861e+01,\n",
      "         -2.1428e+01, -1.1698e+00,  3.9785e+00,  2.7211e+00, -3.6212e+01],\n",
      "        [-3.5633e+00, -6.7544e+00,  5.7392e+00, -5.9126e+00,  1.4880e+01,\n",
      "         -2.7112e+01,  1.8644e+00,  5.6466e+00,  2.1108e+00, -4.3061e+01],\n",
      "        [-3.1990e+00,  7.6794e-01,  5.4857e+00, -1.7272e+00,  9.2129e+00,\n",
      "         -1.2171e+01,  7.6770e-01,  5.3577e+00,  5.3836e-01, -2.7009e+01],\n",
      "        [-2.8669e+00, -2.7405e+00,  3.0227e+00,  9.0301e+00, -6.4444e-01,\n",
      "         -1.3259e+01, -1.8793e+00,  9.8750e+00,  1.2488e+00, -1.8953e+01],\n",
      "        [-7.5263e-01, -4.4785e+00,  7.0335e+00, -5.8877e+00,  8.6866e+00,\n",
      "         -1.5879e+01, -2.2592e+00,  6.1511e+00,  2.9956e+00, -3.1581e+01],\n",
      "        [ 4.5491e+00,  3.9777e+00,  1.2489e+01, -2.3488e+00,  1.4094e+01,\n",
      "         -2.3086e+01,  4.1202e-01,  2.3902e+00, -1.7025e+00, -2.8994e+01],\n",
      "        [-8.4481e-01,  2.7926e+00, -2.2915e+00,  6.1345e+00,  8.3379e+00,\n",
      "         -1.8865e+01, -1.4761e+01,  9.1346e+00,  2.5710e-01, -3.1186e+01],\n",
      "        [-2.4362e+00,  1.4474e+00,  1.0541e+01,  3.3887e+00,  1.3437e+01,\n",
      "         -1.5822e+01, -2.2754e+00,  6.4596e+00, -9.4800e+00, -4.2987e+01],\n",
      "        [-8.9675e+00, -8.8333e+00,  2.3600e+00, -1.1249e+01,  1.0726e+01,\n",
      "         -1.6952e+01,  4.1661e+00,  7.3108e+00, -6.1604e+00, -3.3277e+01],\n",
      "        [ 8.6123e-02,  4.0228e+00,  5.1139e+00, -3.3810e-01,  1.6863e+01,\n",
      "         -6.4540e+00, -2.2419e+00,  5.7307e+00, -5.5546e+00, -3.3873e+01],\n",
      "        [-1.3072e+00, -2.6813e+00,  1.2005e+01,  4.9508e+00,  1.1666e+01,\n",
      "         -1.7626e+01,  5.6917e+00,  4.5501e+00, -1.2274e-01, -2.5712e+01],\n",
      "        [-6.6975e+00, -2.3504e+00,  7.8859e+00,  6.3933e-01,  1.4546e+01,\n",
      "         -1.4485e+01, -1.2561e+01,  2.2465e+00, -3.3517e+00, -3.4993e+01],\n",
      "        [ 2.3283e+00, -9.4655e-01,  3.4658e+00, -1.1260e+00,  1.0067e+01,\n",
      "         -2.0159e+01,  3.2437e-01, -9.4949e+00, -5.0476e+00, -3.7177e+01],\n",
      "        [ 1.0422e+00,  2.3011e+00,  2.1688e+00, -1.0182e+01,  1.5687e+01,\n",
      "         -1.5150e+01, -5.4734e+00, -3.7028e+00,  3.3008e+00, -3.0256e+01],\n",
      "        [-4.3650e+00, -9.5942e+00,  6.0224e+00,  2.3227e+00,  3.1312e+00,\n",
      "         -1.8864e+01,  1.0899e+01,  2.7588e+00, -2.7826e+00, -3.2036e+01],\n",
      "        [-1.1761e+01,  3.1888e+00,  1.2549e+00,  1.4707e+01,  1.1805e+01,\n",
      "         -1.0601e+01, -9.3806e+00,  8.4637e+00,  1.6123e+00, -2.7611e+01],\n",
      "        [-1.8149e+00,  9.4891e+00,  7.1635e+00, -8.6573e-01,  8.7861e+00,\n",
      "         -1.8959e+01, -1.2862e+01,  7.2989e+00, -3.8180e+00, -2.6550e+01],\n",
      "        [-5.3490e+00, -4.7639e-01,  6.0890e+00,  1.9902e+00,  8.2216e+00,\n",
      "         -1.2219e+01,  1.7144e+00,  7.0186e+00, -6.6672e+00, -4.1774e+01],\n",
      "        [ 7.1059e+00,  3.9806e+00, -4.4128e+00, -9.5132e-01,  9.5099e+00,\n",
      "         -1.6408e+01, -2.3045e-01,  1.2683e+01,  3.3372e+00, -3.5965e+01],\n",
      "        [ 1.8380e+00, -5.9869e+00, -4.3670e+00, -6.7883e+00,  1.9442e+01,\n",
      "         -1.8750e+01,  3.7563e+00,  5.0014e+00,  4.9335e+00, -3.3595e+01],\n",
      "        [ 5.5161e+00, -1.0590e+01, -9.0562e-01,  5.1550e+00,  1.2049e+01,\n",
      "         -1.4497e+01, -4.7659e+00,  1.0685e+01,  2.6892e+00, -3.7821e+01],\n",
      "        [-9.2067e+00,  9.0733e+00,  5.3882e+00,  2.6596e+00,  1.1558e+01,\n",
      "         -1.0993e+01, -3.4398e+00,  4.5315e+00, -1.4048e+00, -2.5773e+01],\n",
      "        [-1.7337e-01, -1.0010e+01,  1.4323e+01, -2.5343e+00,  4.5223e+00,\n",
      "         -1.4550e+01, -7.6379e-01,  1.5623e+01, -6.5464e+00, -3.4568e+01],\n",
      "        [-7.5364e+00, -3.1876e+00,  1.5121e+01,  2.9836e+00,  6.8837e+00,\n",
      "         -1.2170e+01, -3.7257e-01,  7.7738e-01,  7.2246e+00, -2.5366e+01],\n",
      "        [ 3.0498e-01, -9.5112e+00,  7.0954e-01, -2.1549e+00,  1.7472e+01,\n",
      "         -1.3844e+01,  1.6732e-01,  6.9604e-01,  2.8688e+00, -3.5362e+01],\n",
      "        [-1.0021e+01, -2.2478e-01,  6.3372e+00,  5.9560e-01,  6.6068e+00,\n",
      "         -2.0794e+01,  3.7782e+00,  5.1959e+00, -2.6008e+00, -2.8505e+01],\n",
      "        [-4.0112e-01,  2.0760e+00,  9.3355e+00, -3.1832e+00,  7.8574e+00,\n",
      "         -1.2920e+01, -9.9973e-01,  8.6713e+00, -1.6830e+00, -3.8042e+01],\n",
      "        [-7.0058e+00,  2.2624e-01,  9.3562e+00, -4.5193e+00,  1.7197e+01,\n",
      "         -2.4005e+01, -6.0759e+00,  1.5698e+00,  4.1893e+00, -2.5376e+01],\n",
      "        [-1.5701e+01,  3.3716e+00,  1.3452e+01,  1.5962e+01,  5.8412e+00,\n",
      "         -1.5050e+01,  5.0216e-01,  1.0377e+00, -2.4281e+00, -2.6525e+01],\n",
      "        [-3.3452e+00,  9.9603e-01, -4.0772e+00, -2.0303e+00,  7.5010e+00,\n",
      "         -1.9127e+01,  6.4780e-01,  6.3679e+00,  1.7035e+00, -3.8920e+01],\n",
      "        [-5.6089e+00, -8.6398e+00,  2.8518e+00, -8.2917e-01,  1.2827e+01,\n",
      "         -1.6728e+01, -4.0987e+00, -3.0592e-01, -3.7690e+00, -3.1689e+01],\n",
      "        [-6.2080e-01, -3.6650e-01,  1.3250e+01,  9.2550e+00,  4.6500e+00,\n",
      "         -1.8239e+01, -3.9200e+00,  7.7584e+00,  3.9239e-01, -2.9109e+01],\n",
      "        [-2.6334e+00, -1.4118e+00,  5.2383e+00,  1.7879e+00,  1.1804e+01,\n",
      "         -1.4456e+01, -4.5100e+00,  1.0931e+01, -6.7568e-01, -2.6785e+01],\n",
      "        [ 4.1971e+00, -5.4342e+00,  6.6963e+00, -4.1434e+00,  1.3590e+01,\n",
      "         -1.7287e+01, -1.6136e+00,  4.0444e+00, -2.3518e+00, -2.6995e+01],\n",
      "        [-5.8992e+00, -9.3835e+00,  1.4437e+01,  1.5985e+00,  1.7199e+01,\n",
      "         -1.3471e+01, -1.4533e+01,  2.0061e+01, -1.2688e+00, -2.2202e+01],\n",
      "        [-8.3842e+00, -4.6307e+00,  6.6429e+00, -4.7645e-01,  6.8712e+00,\n",
      "         -1.2208e+01, -5.3544e+00,  1.3035e+01, -9.7371e-01, -3.6800e+01],\n",
      "        [-1.4164e+00, -9.0507e+00, -6.7089e-02, -1.1884e+01,  2.0450e+00,\n",
      "         -1.4891e+01, -4.9485e-01,  1.8599e+01, -2.4925e+00, -4.3823e+01],\n",
      "        [-1.2894e+01, -4.7935e+00,  1.4345e+01,  1.3088e+01,  1.0337e+01,\n",
      "         -1.0998e+01, -6.6668e+00,  1.4768e+01, -4.3817e+00, -2.3488e+01],\n",
      "        [-5.7162e+00, -1.0696e+01,  5.3545e+00,  4.5413e+00,  3.6646e+00,\n",
      "         -6.2273e+00,  9.9259e-02,  4.5200e+00,  7.2301e+00, -3.6239e+01],\n",
      "        [-1.2634e+01,  1.3563e+00,  3.8103e+00,  9.9576e+00,  6.0305e+00,\n",
      "         -1.3318e+01, -6.2394e+00,  4.4792e+00,  2.8286e+00, -3.9802e+01],\n",
      "        [ 1.5231e-01, -1.8819e+00,  1.1038e+01,  2.1513e+00,  1.1692e+01,\n",
      "         -2.0933e+01, -1.8774e+00,  9.3509e+00, -6.7424e+00, -3.4478e+01],\n",
      "        [-9.4495e+00, -3.6111e+00,  7.0959e+00,  6.5863e+00,  8.4456e+00,\n",
      "         -1.5624e+01, -1.8789e+01,  1.0123e+01, -3.4151e+00, -2.9838e+01],\n",
      "        [ 3.9306e-01, -7.9756e+00,  5.0364e-01,  1.8271e+00,  8.8336e+00,\n",
      "         -1.0570e+01, -2.5474e+00,  1.2659e+01,  2.1365e-01, -2.5363e+01],\n",
      "        [ 9.1756e+00, -1.5106e+01,  3.6129e+00, -6.1525e+00,  5.6520e+00,\n",
      "         -1.8768e+01, -1.6853e+00,  7.4111e+00,  3.1177e+00, -3.6861e+01],\n",
      "        [-2.0648e+00,  1.5423e+00,  2.2562e+00, -1.8230e+00,  1.8535e+01,\n",
      "         -1.4580e+01, -5.4611e+00,  8.8300e+00, -5.4135e+00, -3.6509e+01],\n",
      "        [ 4.3913e+00, -5.5040e+00,  9.1160e+00, -6.0865e+00,  1.7531e+01,\n",
      "         -7.7797e+00, -7.8439e+00, -1.3905e+00, -2.5372e-02, -4.0718e+01],\n",
      "        [-5.5656e+00, -1.0495e+01,  1.7098e+01, -3.4911e-01,  4.1832e+00,\n",
      "         -1.7831e+01, -2.7924e-01,  1.5528e+01, -4.7639e+00, -3.3515e+01],\n",
      "        [-5.5523e+00, -4.9313e+00, -4.8713e+00, -6.9279e+00,  2.1417e+00,\n",
      "         -1.6534e+01,  4.2587e-01,  1.1125e+01, -9.6435e-01, -4.1073e+01],\n",
      "        [ 2.1730e+00, -7.8684e+00,  1.4444e+01,  6.6764e-01,  5.2859e+00,\n",
      "         -1.9087e+01,  7.8150e+00,  8.6831e+00,  3.1644e+00, -3.5396e+01],\n",
      "        [-2.9749e+00, -4.4513e+00,  1.6435e-01,  1.3200e+00,  3.9836e+00,\n",
      "         -1.6047e+01, -8.8217e+00, -2.6903e+00, -2.9860e+00, -3.9253e+01],\n",
      "        [ 1.9713e-01, -2.3130e+00, -4.8535e+00, -3.4945e+00,  5.0801e+00,\n",
      "         -1.7325e+01,  5.2407e+00,  3.8682e+00,  5.0744e-01, -2.9019e+01],\n",
      "        [-9.4547e+00, -3.1573e+00,  1.2671e+00,  7.3677e+00,  1.2619e+01,\n",
      "         -1.4265e+01, -9.2470e+00,  3.9642e+00, -2.2495e+00, -3.4533e+01],\n",
      "        [-4.0461e+00, -5.2526e+00,  3.5944e+00,  1.5044e+00,  8.5398e+00,\n",
      "         -1.1964e+01, -5.1186e+00,  3.5904e+00, -1.8646e+00, -2.4981e+01],\n",
      "        [ 4.1840e+00, -1.0354e+01,  5.7775e+00,  1.5887e+00,  1.0042e+01,\n",
      "         -8.9193e+00, -2.1957e+00, -3.1743e+00, -6.9989e+00, -3.3421e+01],\n",
      "        [-1.0005e+01,  7.7329e+00, -2.1043e-02,  2.4046e+00,  1.4568e+01,\n",
      "         -1.8986e+01, -1.0977e+01,  1.3599e+01,  7.4876e-02, -3.7187e+01],\n",
      "        [-1.3911e+00,  1.6522e+00,  6.6669e+00, -6.7412e+00,  7.3287e-01,\n",
      "         -1.5250e+01, -8.5406e+00,  1.2809e+01, -4.6457e+00, -3.3981e+01],\n",
      "        [-8.2559e+00,  1.2909e+00,  7.9602e+00,  2.2033e+00,  1.1566e+00,\n",
      "         -8.7578e+00, -4.8774e+00,  9.1298e+00,  6.0235e+00, -3.0028e+01],\n",
      "        [-1.7051e-01, -7.4080e+00,  3.1527e+00, -3.9704e+00,  7.4064e+00,\n",
      "         -2.0916e+01, -7.3558e+00,  5.9853e+00,  2.5124e+00, -2.4917e+01],\n",
      "        [-1.0305e+01,  1.2119e+00,  1.3947e+01,  1.5106e+01,  1.4790e+00,\n",
      "         -1.3602e+01, -4.3776e+00,  1.4098e+01, -1.4290e+00, -2.4385e+01],\n",
      "        [-1.1443e+01,  3.7090e+00,  1.7146e+00,  1.1333e+01,  1.0331e+01,\n",
      "         -1.7272e+01, -1.5638e+01, -1.7470e+00, -2.4618e+00, -3.0903e+01],\n",
      "        [ 5.5114e+00, -9.7452e+00,  1.4316e+00,  7.3878e+00,  7.0207e+00,\n",
      "         -2.4958e+01, -5.3620e+00,  6.2942e+00, -3.2987e+00, -3.6451e+01],\n",
      "        [ 1.2570e+00, -1.3332e+00,  3.3979e+00, -1.5173e+00,  6.1051e+00,\n",
      "         -5.0153e+00, -1.5149e+00,  8.6816e+00, -9.0797e-01, -3.5534e+01],\n",
      "        [-2.3889e+00, -8.9790e+00,  2.2117e+00,  1.0479e+00,  8.6590e+00,\n",
      "         -1.0527e+01, -4.8173e+00,  3.8557e+00, -3.1437e+00, -3.2162e+01],\n",
      "        [-7.9217e+00,  2.2650e+00,  5.1766e+00,  7.0076e+00,  9.0271e+00,\n",
      "         -1.9096e+01, -7.5843e+00,  2.2953e+00,  1.2006e+01, -2.7142e+01]])\n"
     ]
    }
   ],
   "source": [
    "## Your solution\n",
    "def activiation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "flattened_images = images.view(images.shape[0], -1)\n",
    "\n",
    "W1 = torch.randn(784, 256)\n",
    "B1 = torch.randn(256)\n",
    "\n",
    "h = activiation(torch.mm(flattened_images, W1) + B1)\n",
    "\n",
    "W2 = torch.randn(256, 10)\n",
    "B2 = torch.randn(10)\n",
    "\n",
    "out = torch.mm(h, W2) + B2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to. Something that looks like this:\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "Here we see that the probability for each class is roughly the same. This is representing an untrained network, it hasn't seen any data yet so it just returns a uniform distribution with equal probabilities for each class.\n",
    "\n",
    "To calculate this probability distribution, we often use the [**softmax** function](https://en.wikipedia.org/wiki/Softmax_function). Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one.\n",
    "\n",
    "> **Exercise:** Implement a function `softmax` that performs the softmax calculation and returns probability distributions for each example in the batch. Note that you'll need to pay attention to the shapes when doing this. If you have a tensor `a` with shape `(64, 10)` and a tensor `b` with shape `(64,)`, doing `a/b` will give you an error because PyTorch will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. The way to think about this is for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need `b` to have a shape of `(64, 1)`. This way PyTorch will divide the 10 values in each row of `a` by the one value in each row of `b`. Pay attention to how you take the sum as well. You'll need to define the `dim` keyword in `torch.sum`. Setting `dim=0` takes the sum across the rows while `dim=1` takes the sum across the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n",
      "tensor([[1.5134e-03, 8.3680e-09, 5.0367e-03, 7.2146e-03, 9.8606e-01, 1.2659e-15,\n",
      "         7.9535e-07, 1.3691e-04, 3.8939e-05, 4.8056e-22],\n",
      "        [9.7733e-09, 4.0193e-10, 1.0716e-04, 9.3267e-10, 9.9979e-01, 5.7918e-19,\n",
      "         2.2246e-06, 9.7685e-05, 2.8461e-06, 6.8585e-26],\n",
      "        [3.8916e-06, 2.0556e-04, 2.3007e-02, 1.6955e-05, 9.5616e-01, 4.9384e-10,\n",
      "         2.0551e-04, 2.0242e-02, 1.6339e-04, 1.7765e-16],\n",
      "        [2.0448e-06, 2.3203e-06, 7.3874e-04, 3.0023e-01, 1.8874e-05, 6.2752e-11,\n",
      "         5.4899e-06, 6.9888e-01, 1.2533e-04, 2.1106e-13],\n",
      "        [6.2430e-05, 1.5041e-06, 1.5027e-01, 3.6752e-07, 7.8483e-01, 1.6823e-11,\n",
      "         1.3838e-05, 6.2178e-02, 2.6498e-03, 2.5517e-18],\n",
      "        [5.9598e-05, 3.3657e-05, 1.6733e-01, 6.0189e-08, 8.3257e-01, 5.9367e-17,\n",
      "         9.5174e-07, 6.8806e-06, 1.1487e-07, 1.6134e-19],\n",
      "        [3.0845e-05, 1.1719e-03, 7.2590e-06, 3.3132e-02, 3.0003e-01, 4.6061e-13,\n",
      "         2.7897e-11, 6.6553e-01, 9.2841e-05, 2.0530e-18],\n",
      "        [1.2092e-07, 5.8766e-06, 5.2278e-02, 4.0948e-05, 9.4679e-01, 1.8580e-13,\n",
      "         1.4202e-07, 8.8290e-04, 1.0555e-10, 2.9610e-25],\n",
      "        [2.7063e-09, 3.0948e-09, 2.2482e-04, 2.7644e-10, 9.6664e-01, 9.2178e-13,\n",
      "         1.3685e-03, 3.1765e-02, 4.4821e-08, 7.4947e-20],\n",
      "        [5.1763e-08, 2.6526e-06, 7.8986e-06, 3.3867e-08, 9.9997e-01, 7.4761e-11,\n",
      "         5.0462e-09, 1.4636e-05, 1.8377e-10, 9.2419e-23],\n",
      "        [9.6418e-07, 2.4400e-07, 5.8278e-01, 5.0343e-04, 4.1532e-01, 7.8868e-14,\n",
      "         1.0562e-03, 3.3725e-04, 3.1517e-06, 2.4280e-17],\n",
      "        [5.9341e-10, 4.5841e-08, 1.2789e-03, 9.1134e-07, 9.9872e-01, 2.4616e-13,\n",
      "         1.6855e-12, 4.5465e-06, 1.6842e-08, 3.0520e-22],\n",
      "        [4.3487e-04, 1.6448e-05, 1.3563e-03, 1.3747e-05, 9.9812e-01, 7.4530e-14,\n",
      "         5.8623e-05, 3.1886e-09, 2.7231e-07, 3.0312e-21],\n",
      "        [4.3646e-07, 1.5370e-06, 1.3466e-06, 5.8255e-12, 9.9999e-01, 4.0517e-14,\n",
      "         6.4600e-10, 3.7950e-09, 4.1766e-06, 1.1148e-20],\n",
      "        [2.3305e-07, 1.2486e-09, 7.5618e-03, 1.8702e-04, 4.1976e-04, 1.1770e-13,\n",
      "         9.9154e-01, 2.8926e-04, 1.1341e-06, 2.2400e-19],\n",
      "        [3.0283e-12, 9.4117e-06, 1.3608e-06, 9.4619e-01, 5.1959e-02, 9.6589e-12,\n",
      "         3.2723e-11, 1.8388e-03, 1.9454e-06, 3.9597e-19],\n",
      "        [7.2285e-06, 5.8660e-01, 5.7323e-02, 1.8676e-05, 2.9042e-01, 2.5899e-13,\n",
      "         1.1520e-10, 6.5632e-02, 9.7524e-07, 1.3087e-16],\n",
      "        [8.9811e-07, 1.1735e-04, 8.3325e-02, 1.3825e-03, 7.0301e-01, 9.3293e-10,\n",
      "         1.0493e-03, 2.1111e-01, 2.4036e-07, 1.3618e-22],\n",
      "        [3.6162e-03, 1.5885e-04, 3.5957e-08, 1.1457e-06, 4.0022e-02, 2.2206e-13,\n",
      "         2.3558e-06, 9.5612e-01, 8.3473e-05, 7.1245e-22],\n",
      "        [2.2632e-08, 9.0451e-12, 4.5699e-11, 4.0585e-12, 1.0000e+00, 2.5897e-17,\n",
      "         1.5411e-07, 5.3525e-07, 5.0013e-07, 9.2539e-24],\n",
      "        [1.1563e-03, 1.1708e-10, 1.8800e-06, 8.0585e-04, 7.9471e-01, 2.3532e-12,\n",
      "         3.9598e-08, 2.0326e-01, 6.8450e-05, 1.7464e-22],\n",
      "        [8.8314e-10, 7.6726e-02, 1.9254e-03, 1.2575e-04, 9.2040e-01, 1.4805e-10,\n",
      "         2.8220e-07, 8.1745e-04, 2.1595e-06, 5.6418e-17],\n",
      "        [1.0844e-07, 5.7951e-12, 2.1421e-01, 1.0229e-08, 1.1872e-05, 6.1901e-14,\n",
      "         6.0088e-08, 7.8577e-01, 1.8511e-10, 1.2522e-22],\n",
      "        [1.4449e-10, 1.1181e-08, 9.9936e-01, 5.3528e-06, 2.6447e-04, 1.4040e-12,\n",
      "         1.8665e-07, 5.8945e-07, 3.7192e-04, 2.6088e-18],\n",
      "        [3.5035e-08, 1.9116e-12, 5.2505e-08, 2.9937e-09, 1.0000e+00, 2.5096e-14,\n",
      "         3.0530e-08, 5.1801e-08, 4.5495e-07, 1.1334e-23],\n",
      "        [2.9027e-08, 5.2124e-04, 3.6886e-01, 1.1839e-03, 4.8302e-01, 6.0788e-13,\n",
      "         2.8544e-02, 1.1782e-01, 4.8433e-05, 2.7235e-16],\n",
      "        [3.3885e-05, 4.0346e-04, 5.7353e-01, 2.0979e-06, 1.3081e-01, 1.2397e-10,\n",
      "         1.8623e-05, 2.9518e-01, 9.4037e-06, 1.5240e-21],\n",
      "        [3.0823e-11, 4.2628e-08, 3.9334e-04, 3.7044e-10, 9.9960e-01, 1.2770e-18,\n",
      "         7.8110e-11, 1.6338e-07, 2.2430e-06, 3.2429e-19],\n",
      "        [1.6415e-14, 3.1489e-06, 7.5141e-02, 9.2482e-01, 3.7212e-05, 3.1466e-14,\n",
      "         1.7864e-07, 3.0519e-07, 9.5364e-09, 3.2684e-19],\n",
      "        [1.4670e-05, 1.1267e-03, 7.0558e-06, 5.4641e-05, 7.5317e-01, 2.0528e-12,\n",
      "         7.9540e-04, 2.4255e-01, 2.2859e-03, 5.2038e-21],\n",
      "        [9.8449e-09, 4.7527e-10, 4.6523e-05, 1.1723e-06, 9.9995e-01, 1.4594e-13,\n",
      "         4.4575e-08, 1.9783e-06, 6.1988e-08, 4.6439e-20],\n",
      "        [9.2502e-07, 1.1929e-06, 9.7779e-01, 1.7995e-02, 1.7999e-04, 2.0631e-14,\n",
      "         3.4144e-08, 4.0291e-03, 2.5479e-06, 3.9251e-19],\n",
      "        [3.7821e-07, 1.2831e-06, 9.9173e-04, 3.1468e-05, 7.0471e-01, 2.7738e-12,\n",
      "         5.7908e-08, 2.9426e-01, 2.6790e-06, 1.2269e-17],\n",
      "        [8.3218e-05, 5.4627e-09, 1.0130e-03, 1.9860e-08, 9.9883e-01, 3.8885e-14,\n",
      "         2.4927e-07, 7.1437e-05, 1.1915e-07, 2.3641e-18],\n",
      "        [5.0111e-12, 1.5372e-13, 3.4018e-03, 9.0393e-09, 5.3892e-02, 2.5801e-15,\n",
      "         8.9217e-16, 9.4271e-01, 5.1392e-10, 4.1667e-19],\n",
      "        [4.9667e-10, 2.1194e-08, 1.6683e-03, 1.3501e-06, 2.0960e-03, 1.0846e-11,\n",
      "         1.0278e-08, 9.9623e-01, 8.2112e-07, 2.2664e-22],\n",
      "        [2.0306e-09, 9.8189e-13, 7.8272e-09, 5.7748e-14, 6.4699e-08, 2.8558e-15,\n",
      "         5.1031e-09, 1.0000e+00, 6.9223e-10, 7.7768e-28],\n",
      "        [5.2306e-13, 1.7238e-09, 3.5337e-01, 1.0055e-01, 6.4233e-03, 3.4841e-12,\n",
      "         2.6480e-10, 5.3966e-01, 2.6022e-09, 1.3109e-17],\n",
      "        [1.8111e-06, 1.2453e-08, 1.1639e-01, 5.1611e-02, 2.1479e-02, 1.0864e-06,\n",
      "         6.0755e-04, 5.0524e-02, 7.5938e-01, 1.0050e-19],\n",
      "        [1.5029e-10, 1.7904e-04, 2.0831e-03, 9.7371e-01, 1.9183e-02, 7.5866e-11,\n",
      "         8.9984e-08, 4.0662e-03, 7.8048e-04, 2.3879e-22],\n",
      "        [6.0229e-06, 7.8773e-07, 3.2182e-01, 4.4460e-05, 6.1861e-01, 4.1940e-15,\n",
      "         7.9128e-07, 5.9524e-02, 6.1020e-09, 5.4988e-21],\n",
      "        [2.4992e-09, 8.5778e-07, 3.8317e-02, 2.3018e-02, 1.4775e-01, 5.2022e-12,\n",
      "         2.1960e-13, 7.9091e-01, 1.0435e-06, 3.4937e-18],\n",
      "        [4.6071e-06, 1.0690e-09, 5.1458e-06, 1.9330e-05, 2.1336e-02, 7.9837e-11,\n",
      "         2.4345e-07, 9.7863e-01, 3.8505e-06, 3.0038e-17],\n",
      "        [8.2852e-01, 2.3599e-11, 3.1803e-03, 1.8256e-07, 2.4436e-02, 6.0585e-13,\n",
      "         1.5904e-05, 1.4191e-01, 1.9383e-03, 8.4107e-21],\n",
      "        [1.1309e-09, 4.1680e-08, 8.5116e-08, 1.4402e-09, 9.9994e-01, 4.1517e-15,\n",
      "         3.7880e-11, 6.0949e-05, 3.9726e-11, 1.2430e-24],\n",
      "        [1.9652e-06, 9.9067e-11, 2.2149e-04, 5.5332e-11, 9.9978e-01, 1.0177e-11,\n",
      "         9.5442e-12, 6.0591e-09, 2.3729e-08, 5.0435e-26],\n",
      "        [1.1888e-10, 8.5952e-13, 8.2780e-01, 2.1909e-08, 2.0369e-06, 5.6018e-16,\n",
      "         2.3494e-08, 1.7220e-01, 2.6504e-10, 8.6485e-23],\n",
      "        [5.7160e-08, 1.0636e-07, 1.1294e-07, 1.4443e-08, 1.2548e-04, 9.7215e-13,\n",
      "         2.2562e-05, 9.9985e-01, 5.6185e-06, 2.1422e-23],\n",
      "        [4.6643e-06, 2.0316e-10, 9.9543e-01, 1.0352e-06, 1.0488e-04, 2.7270e-15,\n",
      "         1.3154e-03, 3.1339e-03, 1.2570e-05, 2.2533e-22],\n",
      "        [8.6799e-04, 1.9831e-04, 2.0040e-02, 6.3647e-02, 9.1323e-01, 1.8258e-09,\n",
      "         2.5079e-06, 1.1538e-03, 8.5842e-04, 1.5248e-19],\n",
      "        [3.0411e-03, 2.4710e-04, 1.9480e-05, 7.5818e-05, 4.0151e-01, 7.4665e-11,\n",
      "         4.7146e-01, 1.1950e-01, 4.1476e-03, 6.2337e-16],\n",
      "        [2.5780e-10, 1.4003e-07, 1.1688e-05, 5.2140e-03, 9.9460e-01, 2.1008e-12,\n",
      "         3.1731e-10, 1.7340e-04, 3.4712e-07, 3.3104e-21],\n",
      "        [3.3691e-06, 1.0082e-06, 7.0103e-03, 8.6709e-04, 9.8510e-01, 1.2264e-09,\n",
      "         1.1527e-06, 6.9823e-03, 2.9848e-05, 2.7256e-15],\n",
      "        [2.8088e-03, 1.3644e-09, 1.3821e-02, 2.0961e-04, 9.8315e-01, 5.7259e-09,\n",
      "         4.7628e-06, 1.7899e-06, 3.9071e-08, 1.3093e-19],\n",
      "        [1.5414e-11, 7.7886e-04, 3.3416e-07, 3.7790e-06, 7.2447e-01, 1.9383e-15,\n",
      "         5.8323e-12, 2.7474e-01, 3.6780e-07, 2.4165e-23],\n",
      "        [6.7930e-07, 1.4249e-05, 2.1460e-03, 3.2253e-09, 5.6820e-06, 6.5022e-13,\n",
      "         5.3346e-10, 9.9783e-01, 2.6220e-08, 4.7696e-21],\n",
      "        [2.0745e-08, 2.9042e-04, 2.2882e-01, 7.2324e-04, 2.5394e-04, 1.2559e-08,\n",
      "         6.0842e-07, 7.3692e-01, 3.2989e-02, 7.2659e-18],\n",
      "        [4.0528e-04, 2.9144e-07, 1.1246e-02, 9.0673e-06, 7.9135e-01, 3.9633e-13,\n",
      "         3.0705e-07, 1.9106e-01, 5.9283e-03, 7.2518e-15],\n",
      "        [5.4857e-12, 5.5075e-07, 1.8690e-01, 5.9575e-01, 7.1938e-07, 2.0291e-13,\n",
      "         2.0580e-09, 2.1735e-01, 3.9268e-08, 4.2101e-18],\n",
      "        [9.3869e-11, 3.5731e-04, 4.8625e-05, 7.3105e-01, 2.6854e-01, 2.7614e-13,\n",
      "         1.4155e-12, 1.5258e-06, 7.4659e-07, 3.3203e-19],\n",
      "        [7.0133e-02, 1.6599e-08, 1.1861e-03, 4.5797e-01, 3.1727e-01, 4.1029e-15,\n",
      "         1.3295e-06, 1.5343e-01, 1.0466e-05, 4.1873e-20],\n",
      "        [5.5124e-04, 4.1346e-05, 4.6898e-03, 3.4395e-05, 7.0285e-02, 1.0407e-06,\n",
      "         3.4478e-05, 9.2430e-01, 6.3258e-05, 5.7969e-20],\n",
      "        [1.5758e-05, 2.1650e-08, 1.5687e-03, 4.8990e-04, 9.8980e-01, 4.6065e-09,\n",
      "         1.3896e-06, 8.1193e-03, 7.4081e-06, 1.8503e-18],\n",
      "        [2.0919e-09, 5.5538e-05, 1.0210e-03, 6.3714e-03, 4.8008e-02, 2.9352e-14,\n",
      "         2.9315e-09, 5.7241e-05, 9.4449e-01, 9.3995e-18]])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through this bit by bit.\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network (`net`) is created with `net.hidden.weight` and `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n",
    "\n",
    "Now we can create a `Network` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "So far we've only been looking at the softmax activation, but in general any function can be used as an activation function. The only requirement is that for a network to approximate a non-linear function, the activation functions must be non-linear. Here are a few more examples of common activation functions: Tanh (hyperbolic tangent), and ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "In practice, the ReLU function is used almost exclusively as the activation function for hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn to Build a Network\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercise:** Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the `nn.ReLU` module or `F.relu` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Your solution here\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__(self)\n",
    "        self.hidden_1 = nn.Linear(782, 128)\n",
    "        self.hidden_2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_1_output = F.relu(self.hidden_1(x))\n",
    "        hidden_2_output = F.relu(self.hidden_2(hidden_1_output))\n",
    "        output = F.softmax(self.output(hidden_2_output), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0253, -0.0080,  0.0265,  ...,  0.0123,  0.0040,  0.0132],\n",
      "        [-0.0025, -0.0075,  0.0234,  ...,  0.0185, -0.0244,  0.0303],\n",
      "        [-0.0272, -0.0051,  0.0239,  ..., -0.0213,  0.0098, -0.0181],\n",
      "        ...,\n",
      "        [-0.0231, -0.0186,  0.0079,  ...,  0.0202,  0.0011, -0.0031],\n",
      "        [-0.0226, -0.0075, -0.0167,  ..., -0.0109, -0.0297,  0.0069],\n",
      "        [-0.0240, -0.0112, -0.0055,  ..., -0.0187,  0.0149,  0.0219]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.2743e-02,  3.5259e-02,  2.9894e-02,  9.3175e-03, -9.6202e-03,\n",
      "         2.9181e-02, -7.1659e-03,  3.5032e-02,  1.8074e-02, -1.2112e-02,\n",
      "         2.7806e-02, -1.7996e-03,  1.6365e-03,  1.4763e-02,  7.5032e-03,\n",
      "        -1.9814e-02, -5.4490e-03, -3.2893e-02,  2.4813e-02,  2.5139e-02,\n",
      "         1.1839e-02,  2.5572e-02, -3.4455e-02, -2.1590e-02,  3.1150e-02,\n",
      "         2.7895e-02, -2.4142e-02, -2.1062e-02,  2.7944e-02,  5.0593e-03,\n",
      "         1.2303e-02, -3.1208e-02,  1.3561e-02, -4.5993e-03,  2.3172e-02,\n",
      "         1.7338e-02, -3.3541e-02,  5.0842e-03, -3.5245e-02, -2.0442e-02,\n",
      "        -2.1884e-02,  8.6870e-03,  1.0369e-02,  1.9094e-02,  1.3779e-02,\n",
      "         1.7881e-02, -8.3718e-03, -3.0333e-02,  1.5593e-02, -1.8307e-02,\n",
      "         1.1768e-02,  2.2213e-02, -1.8321e-02, -2.9228e-03, -3.4040e-02,\n",
      "        -2.1997e-02,  2.0002e-02, -3.3521e-02, -1.7046e-02,  2.5315e-02,\n",
      "         1.5581e-02, -1.6069e-04,  2.4403e-02,  2.1328e-02, -1.0473e-03,\n",
      "        -2.9574e-02, -2.4286e-02,  2.2760e-02, -1.2049e-02, -1.1280e-02,\n",
      "         1.3956e-03, -2.7398e-02,  3.5544e-02, -4.4874e-03, -6.2351e-03,\n",
      "         5.7969e-03, -2.3722e-02, -1.5582e-02,  1.9017e-02, -1.4822e-02,\n",
      "        -7.6105e-03,  9.2929e-03,  1.2651e-02,  1.6261e-02, -1.5945e-03,\n",
      "        -2.6509e-02,  2.2204e-02, -1.0964e-02,  2.0535e-02,  8.2201e-03,\n",
      "        -9.0806e-03,  3.5004e-02, -2.2386e-02, -2.1560e-02,  1.6465e-02,\n",
      "        -1.1172e-02, -1.1000e-02, -1.0877e-02,  1.1634e-02, -2.4243e-02,\n",
      "         1.5087e-02, -5.2094e-04,  2.4240e-02,  2.4075e-02, -6.0279e-03,\n",
      "         1.4326e-02,  2.8639e-02, -5.8137e-03, -8.4806e-03, -1.7667e-02,\n",
      "        -1.6694e-02, -1.1898e-02,  1.2097e-02,  3.5095e-02,  1.5453e-02,\n",
      "        -3.9358e-03, -3.4514e-02,  1.9950e-02, -2.7324e-02,  1.1118e-03,\n",
      "        -1.7384e-02,  3.1733e-03,  2.3429e-02, -1.2401e-02, -3.4560e-02,\n",
      "        -3.0919e-02, -2.6655e-02,  2.4284e-02, -3.0047e-02,  2.5637e-05,\n",
      "         9.7436e-03,  7.1536e-03, -3.5548e-02, -3.1485e-02, -2.4040e-02,\n",
      "        -3.2479e-02, -3.1157e-02, -3.3424e-02, -2.2105e-03,  2.7164e-03,\n",
      "         2.4829e-02,  1.6872e-02, -2.5962e-02, -1.5192e-02,  3.3653e-02,\n",
      "        -2.9130e-02, -1.0204e-02,  3.3932e-02,  2.7240e-02,  2.8165e-02,\n",
      "        -1.9285e-02,  7.9324e-03, -2.3154e-02,  3.7296e-03, -2.7156e-02,\n",
      "        -1.8329e-02,  3.3358e-02, -4.5286e-03, -2.5933e-02, -2.6979e-02,\n",
      "         1.8199e-02, -3.2841e-02,  1.9409e-02,  2.5854e-02,  2.3073e-02,\n",
      "         3.0997e-02,  1.7527e-02,  3.3289e-02, -7.1943e-03, -2.4667e-02,\n",
      "         6.4641e-03, -3.4616e-02,  5.8662e-03, -1.4733e-02,  1.9766e-03,\n",
      "        -2.7443e-02,  1.1624e-02,  2.8433e-02,  1.1352e-02, -3.5399e-02,\n",
      "        -3.1433e-02,  6.1192e-03,  3.2345e-03,  3.4282e-02, -2.9428e-02,\n",
      "         2.8258e-02, -1.6179e-02, -5.7053e-04, -2.5569e-02,  7.4916e-03,\n",
      "        -2.4324e-02, -3.4052e-03,  3.4334e-02, -7.4980e-03,  2.3204e-02,\n",
      "        -3.2534e-02,  8.5805e-03, -2.7038e-02, -2.3826e-02,  2.4790e-02,\n",
      "         3.3393e-02,  1.9900e-02,  3.9011e-03,  7.5576e-03,  3.0084e-02,\n",
      "         2.6495e-02, -8.3020e-04, -3.0313e-02,  6.0950e-03,  1.5532e-02,\n",
      "        -3.3689e-02, -3.1994e-03,  8.7134e-03,  2.2315e-02,  1.4570e-02,\n",
      "        -9.2987e-03, -1.8504e-02,  7.5410e-03, -1.3322e-02,  8.6114e-03,\n",
      "        -1.1408e-02, -2.7729e-02, -1.9446e-02,  2.2614e-02, -3.1679e-02,\n",
      "         6.5657e-03,  3.3196e-02, -2.0732e-02, -1.0130e-02,  1.6806e-02,\n",
      "        -5.5969e-03, -2.2757e-02,  2.3271e-02, -3.3894e-02, -2.0397e-03,\n",
      "        -2.4970e-02, -3.1570e-02,  6.3309e-03,  2.9174e-02,  6.9953e-04,\n",
      "        -9.1508e-03,  3.0325e-03, -2.4555e-02,  1.8082e-02, -1.5446e-02,\n",
      "        -6.0685e-03, -6.2358e-03, -1.1992e-03,  6.9672e-03, -3.1447e-02,\n",
      "        -1.8790e-02, -2.3729e-02,  2.6985e-02, -5.6965e-03, -3.4028e-02,\n",
      "        -1.4509e-02], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden.weight)\n",
    "print(model.hidden.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.hidden.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0014,  0.0094,  0.0282,  ..., -0.0069, -0.0065,  0.0092],\n",
       "        [ 0.0030, -0.0140, -0.0028,  ...,  0.0019,  0.0030,  0.0237],\n",
       "        [ 0.0039, -0.0015,  0.0093,  ...,  0.0030, -0.0154, -0.0119],\n",
       "        ...,\n",
       "        [ 0.0156,  0.0080, -0.0022,  ...,  0.0075, -0.0060,  0.0176],\n",
       "        [-0.0163,  0.0004, -0.0044,  ..., -0.0003, -0.0054,  0.0201],\n",
       "        [ 0.0029, -0.0006, -0.0034,  ..., -0.0268,  0.0029, -0.0181]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.hidden.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 226,
       "width": 423
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!\n",
    "\n",
    "### Using `nn.Sequential`\n",
    "\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHECAYAAAAOFHoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYJVV9N/Dvj1VAFgERReOoAUExQYj7ihpjwmvEBTUG4hJN4oZxeRPcIhpNMO5LEjWKxiVxS9A34kpEJe4ZNYqyaHRUcEEB2QRE5rx/VLW0bffU3J7bffve+Xye5z41XVWn6ndrenrut0+dU9VaCwAAAEvbZtIFAAAArHWCEwAAwADBCQAAYIDgBAAAMEBwAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAYITAADAAMEJAABggOAEAAAwQHACAAAYIDgBADOjqlr/WjfpWrYWk7rmW3LeqnpT3/b4zT1uVT2iX/+x5VXMtBOcAIA1p6p2rqrHVtV/VNV3quqnVXVZVX2rqt5dVUdX1U6TrnO1VNWGeR/o515XV9X5VXVaVT25qnaedJ1bqz5UHV9Vh0y6FlbOdpMuAABgvqq6b5LXJdl33urLkmxMsq5/PTDJC6vqmNbaR1e7xgm6LMml/Z93SLJnkjv3r0dX1eGttfMmVdwU+X6Ss5L8eIQ2F/VtvrPItkckuVuSDUm+tIW1sUbpcQIA1oyqekSS96QLTWclOSbJ3q21a7fWdkuyR5IHJflYkhskuetkKp2YF7fW9u1feybZO8kLkrQkt0gXOBnQWnt6a+3A1tqrR2hzUt/mj1ayNtYuwQkAWBOq6jeSvCbd55P3J7l1a+2trbXz5/ZprV3UWvu31trhSR6S5JLJVLs2tNbOb609K8kb+1X3q6obTLImmFWCEwCwVrwgyY5Jzk3ysNba5ZvaubX2ziQv3ZwDV9W2VXV4Vb2iqtZX1Q+r6mdV9b2qOqmq7rGJttv0Y1hO7ccUXVVVP6qqr1bViVV1n0Xa3KSq/rGqzq6qy/sxWt+uqo9V1dOrau/NqXsE/zrvz4fOq+MXkyBU1Y5V9cyq+nJVXdKv32NB3YdX1b9X1Q/66/ODoeuzoP3BVfX2vt0VVXVmVT27qnZcYv9rV9VRVfW2qjq9qn7SX69vVNXrqmr/FTrvkpNDbOIcvzI5xNy6dLfpJckbF4xD29Dvd2L/9bsHzvHcfr9PbW5drB5jnACAiauq/ZIc0X/5ytbaRZvTrrXWNvMUByWZPxbqyiQ/S3L9JEcmObKqntla+5tF2r4lycPmfX1Rkt3S3SZ3i/71wbmNVXVoulsJd+1XXZVubNKv9a+7Jfni/DZjcO68P++2yPZrJflEktv29fx04Q5V9fwkz+y/bOne5z655vqc0Fp7+iZquGO6WwV3SXJxkkpy8yTPS/J7VfXbrbVLF7R5RJJXzfv6knS/2L9Z/3pYVR3ZWjtlzOcdl8uT/DDdWLPt+/PPD/w/6pevT/LIJPetqr3m96LOqapK8vD+yxNXqF62gB4nAGAtuHu6D7xJ8v9W4Pg/S/KuJPdNN35qp9batZNcL8mzk1yd5PlVdbv5jarqrulC08YkT06yW2ttj3RB5AbpPvj/14JzvThdaPpskkNbazu01q6T7oP9bZK8PF0oGadfm/fnnyyy/fFJDkjy0CTX7t/DunSBLlX10FwTml6dZJ++5uvmmmBzXFUdvYka/iHJ15L8Rmtt93TX4JHpgsTts3jv4Pn98e+YZI9+HNu10gXdt6W7Zv9SVbuM+bxj0Vp7R2tt3yRzPURPmjcGbd/W2m36/T7V17hDkj9c4nD3THLjdH8n71ipmlk+wQkAWAsO6pdXppsUYqxaa2e31h7cWntfa+2Hcz1VrbXzWmvPT/LcdMHtzxY0vX2//HBr7eWttUv6dq219v3W2j+31p62RJsntda+OK+Gn7bW/ru19uTW2qfH/BYfM3eaJJ9fZPu1kzyk/6D/s76eb7fWrup7Ov663+/trbUnttZ+3O9zfmvt2FxzK+Dzq2qpz49XJrlPa+0rfduftdbelORx/fY/rqobz2/QWvvX1tqxrbVPz/Uy9tf2zHQTg5ySLrw9aBPvfeTzTsjr++Ujl9j+qH757rnvM9YWwQkAWAv26pcXjnD73Tj9R7+804L1F/fLfTYRGBaaa3P9La5qE6pqh6q6RVW9Pt307EkXfH60yO5fbq19eIlDHZLk1/s/P3+JfZ7bL2+c7na/xbymtXbBIuvfnOScdJ87779E21/Rfx+c3H+58O9lxc67gt6crufzkKq69fwNVbV7rqnRbXprlOAEAGwVqmqn/kGxH6uq8/pJHlo/uH+uZ2jhjHSnpPuwe2iSj1X34N2hWeve3y/fXFUnVNXtq2r7Mb2N58yr+cokX03yx/22z+SaXpaFNtXDNTeZxI9aa19dbIfW2lm5ZhzVoYvtk25c12JtNyY5bam2VXXDqnphP2nHT6p7sO/ce3xZv9umrvmyzrva+nFN7+m/XNjr9LB0tyh+vbX2iVUtjM0mOAEAa8HcYPnr9LeOjVVVXT/dg0lfmm5yhuumCx4/Sje4f+5BqL80lqa19o0kj003XuYu6SaKOLeqvtXPmvdLPQe9/5tuzMuuSf4yXWi5uKo+WlWPraqdtuCtXNbX+8Mk30tyRpJ/T3db211aa4uNb0qumaRgMdftl+duYp+k672Zv/9Cm2o/t+2X2lbV3dK9h79IF252TzdBxNx7nOu929QYp5HPO0Fzt+s9rKp2mLd+7ja9N4Y1S3ACANaCM/rljulmRBu3l6ebHOGb6W5r27N/qO4+/eD+2y/VsLV2YpKbJPnzJO9NF/LWpRsPtb6qnrFg//OT3DnJbyd5ZbrerB2SHJ5uIoPTq+qGy3wf8x+Au19r7RattQf2z7v6+SbaXb0Zx1506u4x+ZUw3PfCvTXd+KtT0j3MeKfW2h5z7zHJU5Zqv9zzTtgpSb6V7tbU30+Sqrplkt9K93f0z5MrjSGCEwCwFnw83cQGSf+Bclz63+zfr//yD1tr/95au3DBbtfb1DH6CSVe0Vo7Ml3vxW2TnJTug/lfV/fw3vn7t9baKa21J7XWDk03dfmfJrkgyU1zzS1oa8Fcb9SvbXKvZC7sLdV7tanb6ebGe81ve4f+mBckuV9r7bTW2hUL2m3y72WZ552YftzW3Bimudv15m61/FBr7XurXxWbS3ACACautXZOrhkb9MSqWuxZRL9iM2/r2zvX9KZ8cYl97rU550t+EYo+n+SoXDP5wJ0H2lzYWntdkrneqbttav9V9oV+uUtVLTrxQ1UdkGS/BfsvtOh76v+O7rJI27kgdnZr7VeeK9XbnL+XUc+7EjbOnXYz9n1jut6l3+ln+5ub4t2kEGuc4AQArBXPSjfu6Ibpnt1zrU3tXFUPzjW3cm3KxbmmN+tWixzn+kmeuMQ5dlhsfZK01q5O9zDZpA9mVbVNVW23iVoun7//GvGlJN/o//yMJfY5vl9uSPK5JfZ5bFXtscj6o5PcKF24+Pd56+eeZbX/Yn/XVXXvdLc3Dhn1vCthbizWYnX8ktbauUk+kGTbdM+qum66HrGVeH4ZYyQ4AQBrQmvtS+ke1NqSHJHki/0sdnvO7VNVu1fVA6rq1HQPCd11M457aboZ55LkxKo6pD/WNlV1z3S3CS7VU/A3VfXuqjpyQR3Xq6pXphv71JJ8pN+0W5JvVNUzq+pWVbXtgnO9oN/vQ8NXZHX0t489q//yflX1qqraK0mqaq/+ff5Bv/1Z/Wx1i7lWkg9W1cF92+2r6uFJXtNvf0Nr7Tvz9v9kkp+mG+/z5j7Azs1++Kgk/5ZrJg3ZlFHPuxLmZiN8QD+1+JC5SSLmpll/a2vtqqV2Zm3Y1G9EAABWVWvtDVV1fpLXJjkw3Sx2qapL0wWU+UHp20k+upmHfnKSU9P1OH2xqi5L9wvkndKNsXlUrpkqer7t0k0m8cC+jovThaz5dTyrtXb6vK9vnO55SM9PclVVXZJutrht++3fzOb1lK2a1to7qupWSZ6Z5AlJHldVF6Wre+4X7Se01t62icM8Lsk/JflK33andJNiJF1w/aX33Fr7SVU9Pckr0t32eFTfbpd01/1L6W5fe+VA+SOdd4W8JcnT0t2y+eOqOi9db+Q5rbXFbuM8Ocn3c80YLLfpTQE9TgDAmtJae0+6CRQen27c0znpPkhvl+5WsXene+7NzTf3mTettc+mm4zgPUkuTLJ9kvPSBbRDkvzPEk1fluTYdLPpnZ0uNO2Y5Lvperzu2lr7m3n7X5zk/6Sbxe9z6W7B2jXdNOKfTxdMDunHdK0prbVnJblnuvf643Sz3Z2f7haye7XWnj5wiE8luV2Sd6a75bIlOSvJXyW5e9/zt/Ccr0zygFzT+7RdkjOTPCfJHdNNTT5k5POOW2vtzHSzKH4w3S2I+6YL0IvOntjPgDj30OXPLwjerFE1mYdzAwDA1quqzk6yf5LHttZeM7Q/kyc4AQDAKurHu52SrifyBq21iweasAa4VQ8AAFZJVe2d5EX9lycKTdNDjxMAAKywqnpxkgenG/+0fbpxZLdsrZ030cLYbHqcAABg5e2d7rlSlyf5cJJ7CE3TRY8TAADAAD1OAAAAAwQnAACAAYITAADAgO0mXcBK+e1tjjJ4C2CN+8jGd9WkawCAzaHHCQAAYMDM9jgBwEqqqm8l2S3JhgmXAsDS1iW5uLV2ky09kOAEAMuz20477bTnQQcdtOekCwFgcWeccUYuv/zysRxLcAKA5dlw0EEH7bl+/fpJ1wHAEg477LB84Qtf2DCOYxnjBAAAMEBwAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAYITAADAAMEJAABggOAEAAAwQHACAAAYIDgBAAAMEJwAAAAGCE4AAAADBCcAAIAB2026AACYVqefe1HWHXfyqp93wwlHrPo5AbZ2epwAAAAGCE4AAAADBCcAAIABghMAAMAAwQkAAGCA4AQAADBAcAJgZlXnUVX1maq6pKp+WlVfrKpjq2rbSdcHwPQQnACYZf+c5A1JbpLkHUn+KckOSV6R5B1VVROsDYAp4gG4AMykqjoyyTFJvpXktq21H/frt0/yziQPTPLwJG+aVI0ATA89TgDMqgf0y5fMhaYkaa1dleTZ/ZdPXPWqAJhKghMAs2rffvnNRbbNrTu0qvZYpXoAmGKCEwCzaq6X6SaLbLvpvD8fuAq1ADDljHECYFa9L8kfJHlKVb29tXZBklTVdkmeO2+/62zqIFW1folNAhfAVkRwAmBWvT3J0Ul+N8nXqur/JflpknsluVmSryfZP8nVE6sQgKkhOAEwk1prG6vq95M8Kd3sesckuSrJp9LNpvfqdMHpvIHjHLbY+r4n6tBx1gzA2iU4ATCzWms/T/KS/vULVbVTkkOSXJ7kqxMoDYApY3IIALZGxyS5VpJ39tOTA8AmCU4AzKyq2m2RdbdJckKSS5M8b9WLAmAquVUPgFn2kaq6PMnpSS5Jcsskv5fkyiQPaK0t9ownAPgVghMAs+zdSR6abna9nZJ8L8nrk5zQWtswwboAmDKCEwAzq7X2oiQvmnQdAEw/Y5wAAAAGCE4AAAADBCcAAIABghMAAMAAwQkAAGCAWfUAYJkO3m/3rD/hiEmXAcAq0OMEAAAwQHACAAAYIDgBAAAMEJwAAAAGCE4AAAADzKrH1KjDbjlym8e9/aSR2/zuzpeM3ObAjz56tP3/6oKRz9EuHr2u5WiX/XRVzrPxiitW5Tzb7rbbyG1aayO32XjJ6vz9sLacfu5FWXfcyRM59waz+QGsKj1OAAAAAwQnAACAAYITAADAAMEJAABggOAEAAAwQHACAAAYIDgBMNOq6oiq+nBVnVNVl1fVN6vqXVV1h0nXBsD0EJwAmFlV9cIk70tyaJIPJnlFki8kuV+ST1bV0RMsD4Ap4gG4AMykqto3ydOS/DDJb7TWzpu37fAkH03yvCRvnUyFAEwTPU4AzKobp/t/7rPzQ1OStNZOTXJJkutOojAApo/gBMCs+nqSnyW5bVXtPX9DVd01ya5JTplEYQBMH7fqATCTWmsXVNVfJnlpkq9V1XuSnJ/kZkl+P8lHkvzpBEsEYIoITkyNbV584chtfmfni0Zus3HkFsnX7vG60RrcYxknWYZtltGp/Mhv33PkNrttf8XIbT5w+mEjt1mOf7zL6MNXvnPVXiO3ec+D7jJym6u/etbIbRhNa+3lVbUhyYlJHjNv0zeSvGnhLXyLqar1S2w6cMsrBGBauFUPgJlVVX+R5N1J3pSup2mXJIcl+WaSt1XV302uOgCmiR4nAGZSVd09yQuTnNRae8q8TV+oqvsnOTvJU6vqNa21by51nNbaot2jfU/UoWMsGYA1TI8TALPq//TLUxduaK39NMnn0v0/eOvVLAqA6SQ4ATCrduyXS005Prf+Z6tQCwBTTnACYFad1i//pKr2m7+hqn43yZ2SXJHkU6tdGADTxxgnAGbVu9M9p+leSc6oqpOS/CDJQelu46skx7XWzp9ciQBMC8EJgJnUWttYVb+X5PFJHprk/kl2TnJBkvcneWVr7cMTLBGAKSI4ATCzWmtXJXl5/wKAZTPGCQAAYIDgBAAAMEBwAgAAGCA4AQAADDA5BFtsu3W/NnKbttOOwzstcM5Fvl1Xwxtu/JFVOc/LbnDa8E6TstOlIzd5/d/daeQ2ex65w8ht2lWe1QoAk+CTKAAs08H77Z71Jxwx6TIAWAVu1QMAABggOAEAAAwQnAAAAAYITgAAAAMEJwAAgAFm1QOAZTr93Iuy7riTJ13GJm0w6x/AWOhxAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAWbV45dst+/1Rm5zzIdOG7nNgTv8YOQ2j3zJk0du84/77z9ym8fu8fWR28Bph/zLyG0OfdqTRm5zw7/91MhtAIAtp8cJgJlUVY+oqjbwunrSdQIwHfQ4ATCrvpTkuUtsu0uSeyT5wOqVA8A0E5wAmEmttS+lC0+/oqo+3f/xdatXEQDTzK16AGxVqurgJLdPcm6SkydcDgBTQnACYGvzp/3yDa01Y5wA2CyCEwBbjaraKcnRSTYmef2EywFgihjjBMDW5MFJ9khycmvtu5vToKrWL7HpwLFVBcCap8cJgK3Jn/TL1060CgCmjh4nALYKVXWLJHdMck6S929uu9baYUscb32SQ8dTHQBrnR4nALYWJoUAYNkEJwBmXlVdK8kx6SaFeMOEywFgCglOAGwNjkpynSTv39xJIQBgPmOc+GU77zRyk/tf+7xlnGj0zH7I0V8Zuc17n3Kvkdu8Y8/7jNxmrbrFk04fuc3G1ApU8quuv+NFI7d5zj5LTW42Xr/1uYeP3ObKM3Yfuc2NPnflyG1YtrlJIV430SoAmFp6nACYaVV1UJI7Z8RJIQBgPj1OAMy01toZySp1pQIws/Q4AQAADBCcAAAABghOAAAAAwQnAACAAYITAADAALPqAcAyHbzf7ll/whGTLgOAVaDHCQAAYIDgBAAAMEBwAgAAGCA4AQAADDA5BL/ksoOuO+kSlnTgLj8Yuc15/7PzyG12+MEPR26zVp3zr5OuYGk/vM5eI7e5950evwKV/KobffLrI7e5+sKvrUAlAMBaITgBwDKdfu5FWXfcyZMuIxvM7Aew4tyqBwAAMEBwAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAYITADOvqu5SVf9WVd+vqiv75Yer6vcmXRsA08FznACYaVX1rCR/neTHSd6X5PtJ9k5y6yR3T/L+iRUHwNQQnACYWVV1VLrQdEqSB7TWLlmwffuJFAbA1HGrHgAzqaq2SfLCJD9N8rCFoSlJWmtXrXphAEwlPU4AzKo7JrlJkncnubCqjkhycJIrknyutfbpSRYHwHQRnGbYtrvtNnKbF7zqtStQyXjceZezRm5z6o1uP/qJfvDD0dswsqsvvHDkNtd63+dWoJJfdfWqnIVVcJt++cMkX0hyq/kbq+oTSR7UWvvRahcGwPQRnACYVfv0yz9L8q0k90ry2SQ3TvKSJL+T5F3pJohYUlWtX2LTgWOpEoCpYIwTALNq235Z6XqW/rO1dmlr7atJ7p/knCR3q6o7TKxCAKaGHicAZtXc/aDfbK39z/wNrbXLq+pDSf44yW2TLDneqbV22GLr+56oQ8dUKwBrnB4nAGbV3MDInyyxfS5Y7bQKtQAw5QQnAGbVJ5L8PMn+VbXDItsP7pcbVq0iAKaW4ATATGqt/TjJO5LsnuSv5m+rqt9ONznERUk+uPrVATBtjHECYJY9Jcntkjyzqu6a5HPpZtW7f7qZ5x/TWlvqVj4A+AXBCYCZ1Vo7r6pul+RZ6cLS7ZNckuTkJH/bWvvMJOsDYHoITgDMtNbaBel6np4y6VoAmF7GOAEAAAwQnAAAAAYITgAAAAOMcZpl24/+1/tbO169AoWMx+vPu9vIbdrnv7IClQAAsLXR4wQAADBAjxMALNPB++2e9SccMekyAFgFepwAAAAGCE4AAAADBCcAAIABghMAAMAAwQkAAGCAWfUAYJlOP/eirDvu5EmXkQ1m9gNYcXqcAAAABghOAAAAAwQnAACAAYITAADAAJNDMDVetN8HR25zm9c8eeQ2O507O/8sWo3eptr46xiXnb8/enF7vf7TK1AJALC10eMEAAAwQHACYGZV1Yaqaku8fjDp+gCYHrNzTxIALO6iJC9fZP2lq10IANNLcAJg1v2ktXb8pIsAYLq5VQ8AAGCAHicAZt2OVXV0kl9LclmSLyf5RGvt6smWBcA0EZwAmHX7JnnLgnXfqqpHttY+PomCAJg+ghMAs+yNSU5L8tUklyS5aZInJPmTJB+oqju01v5nUweoqvVLbDpwnIUCsLYJTgDMrNbacxesOj3Jn1XVpUmemuT4JPdf7boAmD6CEwBbo9ekC053HdqxtXbYYuv7nqhDx1wXAGuUWfUA2Bqd1y93mWgVAEwNwQmArdEd+uU3J1oFAFPDrXpMjV232WHkNmfe9+9XoJLpsc0yfjeyMRtXoJLxuKL9fOQ29zv32JHb7PiBz4/chrWnqm6Z5PuttQsWrL9xklf3X7511QsDYCoJTgDMqqOSHFdVpyb5VrpZ9W6W5Igk10ry/iQvnlx5AEwTwQmAWXVqkpsnuXW6W/N2SfKTJP+V7rlOb2mttcmVB8A0EZwAmEn9w2094BaAsTA5BAAAwADBCQAAYIDgBAAAMEBwAgAAGCA4AQAADDCrHgAs08H77Z71Jxwx6TIAWAV6nAAAAAYITgAAAAPcqjfDrj7/gpHb3PnZx47c5pTnvXTkNjvXDiO3YXTb17Yjt7mqrUAhY7Kc75tHveykkdu846w7j9zm59/cMHIbAGB66HECAAAYIDgBAAAMcKseACzT6edelHXHnTzpMjbLBrP/AWwRPU4AAAADBCcAAIABghMAAMAAwQkAAGCA4AQAADBAcAIAABggOAGwVamqY6qq9a9HT7oeAKaD4ATAVqOqbpTkVUkunXQtAEwXwQmArUJVVZI3Jjk/yWsmXA4AU2a7SRfA2rLniZ8euc0hd3ziyG3+9R6vHbnNrXfcOHKbrd1VbfQ2GzNb1/khu35/5DZvudF1Rm6zzTc3jNyGVXdsknskuXu/BIDNpscJgJlXVQclOSHJK1prn5h0PQBMH8EJgJlWVdsleUuS7yR5xoTLAWBKuVUPgFn3V0luneTOrbXLR21cVeuX2HTgFlUFwFTR4wTAzKqq26brZXpJa230QZwA0NPjBMBMmneL3tlJnr3c47TWDlvi+OuTHLrc4wIwXfQ4ATCrrp3kgCQHJbli3kNvW5Ln9Pv8U7/u5ROrEoCpoMcJgFl1ZZI3LLHt0HTjnv4ryVlJ3MYHwCYJTgDMpH4iiEcvtq2qjk8XnP65tfb61awLgOnkVj0AAIABghMAAMAAwQmArU5r7fjWWrlND4DNJTgBAAAMMDkEW+yAR//3yG3+er/7jtzmnAevG7nNcly8/89HbvP0w9+3ApX8st/Y8bsjt9mmNo7c5swrrz9ym4fs+v2R2wAATBM9TgAAAAMEJwAAgAGCEwAAwABjnABgmQ7eb/esP+GISZcBwCrQ4wQAADBAcAIAABggOAEAAAwQnAAAAAYITgAAAAPMqgcAy3T6uRdl3XEnT+z8G8zoB7Bq9DgBAAAMEJwAAAAGuFWPifj5ud8buc2+Lxu9zXLsu4w2/5Z9xl7HQv9+m3uu+DmSZNvzLxm5zUNOe9cKVAIAsHbocQIAABggOAEAAAwQnAAAAAYITgDMrKp6YVX9Z1V9t6our6oLquqLVfWcqtpr0vUBMD0EJwBm2ZOT7JLkI0lekeRtSX6e5PgkX66qG02uNACmiVn1AJhlu7XWrli4sqpekOQZSZ6e5HGrXhUAU0ePEwAza7HQ1Htnv9x/tWoBYLoJTgBsje7bL7880SoAmBpu1QNg5lXV05JcO8nuSX4ryZ3ThaYTJlkXANNDcAJga/C0JNeb9/UHkzyitfajoYZVtX6JTQeOozAApoNb9QCYea21fVtrlWTfJA9IctMkX6yqQydbGQDTQo8TAFuN1toPk5xUVV9IcnaSNyc5eKDNYYut73uiBC+ArYTgxNTY9ua/PnKbq8/6xgpUMhnt819ZnRPddN3qnGcN+9+jdhi5zf4fX4FCWDGttW9X1deSHFJVe7fWfjzpmgBY29yqB8DW6gb98uqJVgHAVBCcAJhJVXVgVe27yPpt+gfg7pPkU621C1e/OgCmjVv1AJhV90nyoqr6RJL/TXJ+upn17pZucogfJHnM5MoDYJoITgDMqlOSvC7JnZL8ZpI9klyWblKItyR5ZWvtgsmVB8A0EZwAmEmttdOTPH7SdQAwG4xxAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAWbVA4BlOni/3bP+hCMmXQYAq0CPEwAAwAA9TkzExX9w+5HbPOn4d4zc5iMX3nLkNh/79MEjt/n1J39m5DarobbfYeQ2ZzxnzxWoZLpc58YXTroEAGCN0eMEAAAwQHACAAAYIDgBAAAMMMYJAJbp9HMvyrrjTp6iICosAAAP7ElEQVTY+TeY0Q9g1ehxAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAYITAADAAMEJgJlUVXtV1aOr6qSq+kZVXV5VF1XVf1XVH1eV/wMB2Gye4wTArDoqyT8m+X6SU5N8J8n1kjwgyeuT/G5VHdVaa5MrEYBpITgxEVcfff7Ibe5/7fNWpc0Z1/vPkdsc/YMnj7T/jheO/jntgtteNXKbx9z2tJHbvHev147cZtbs+NY9J10C43F2kt9PcnJrbePcyqp6RpLPJXlguhD1b5MpD4Bp4jYFAGZSa+2jrbX/mB+a+vU/SPKa/su7r3phAEwlwQmArdFcF+7PJ1oFAFNDcAJgq1JV2yX5o/7LD06yFgCmhzFOAGxtTkhycJL3t9Y+NLRzVa1fYtOBY60KgDVNjxMAW42qOjbJU5OcmeSYCZcDwBTR4wTAVqGqHp/kFUm+luSerbULNqdda+2wJY63Psmh46sQgLVMjxMAM6+q/jzJq5OcnuTwfmY9ANhsghMAM62q/jLJy5J8KV1oGv0BbwBs9QQnAGZWVT073WQQ69PdnvfjCZcEwJQyxgmAmVRVD0/yvCRXJzktybFVtXC3Da21N61yaQBMIcEJgFl1k365bZI/X2Kfjyd506pUA8BUc6seADOptXZ8a60GXnefdJ0ATAc9TrDAQTuM/vuE9ce+YgUq2XLbLON3IxtXoI5JOvCDjx29zX98eeQ2s3bdAIBfpscJAABggOAEAAAwQHACAAAYIDgBAAAMMDkEACzTwfvtnvUnHDHpMgBYBXqcAAAABghOAAAAAwQnAACAAYITAADAAMEJAABggFn1AGCZTj/3oqw77uQVP88GM/cBTJweJwAAgAF6nICJ+OyV24/c5q+e8JiR2xz40a+M3GbjFVeM3AYAmG16nAAAAAYITgAAAAMEJwAAgAGCEwAAwADBCYCZVVUPqqpXVdVpVXVxVbWqeuuk6wJg+phVD4BZ9qwkv5nk0iTnJDlwsuUAMK30OAEwy56c5IAkuyV57IRrAWCK6XECYGa11k6d+3NVTbIUAKacHicAAIABghMAAMAAt+oBwCZU1folNploAmAroscJAABggB4nJmLv/zv6IO2D/uwJI7fZY91PRm7z6cNm5xEvl268cuQ2h5305JHbbH/R6L+DuenfnT5ymx0v+fzIbTaO3AJ+WWvtsMXW9z1Rh65yOQBMiB4nAACAAYITAADAAMEJAABggDFOAMysqjoyyZH9l/v2yztU1Zv6P/+4tfa0VS8MgKkjOAEwyw5J8vAF627av5Lk20kEJwAGuVUPgJnVWju+tVabeK2bdI0ATAfBCQAAYIDgBAAAMEBwAgAAGCA4AQAADBCcAAAABpiOHACW6eD9ds/6E46YdBkArALBiYm4+mtnj9xm/2NXoJBF/H5uszonWqP2z2dX5TwbV+UsAADj4VY9AACAAYITAADAAMEJAABggOAEAAAwwOQQALBMp597UdYdd/Kqn3eDmfwAVp0eJwAAgAGCEwAAwADBCQAAYIDgBAAAMEBwAgAAGCA4AQAADBCcAJhpVXXDqjqxqr5XVVdW1YaqenlVXWfStQEwPTzHCYCZVVU3S/KpJPskeW+SM5PcNsmTktynqu7UWjt/giUCMCX0OAEwy/4hXWg6trV2ZGvtuNbaPZK8LMnNk7xgotUBMDUEJwBmUlXdNMm9k2xI8vcLNj8nyWVJjqmqXVa5NACmkOAEwKy6R7/8cGtt4/wNrbVLknwyyc5Jbr/ahQEwfQQnAGbVzfvl2Uts/3q/PGAVagFgypkcAoBZtXu/vGiJ7XPr99jUQapq/RKbDlxOUQBMJz1OAGytql+2iVYBwFTQ4wTArJrrUdp9ie27LdhvUa21wxZb3/dEHbq80gCYNnqcAJhVZ/XLpcYw7d8vlxoDBQC/IDgBMKtO7Zf3rqpf+v+uqnZNcqcklyf5zGoXBsD0EZwAmEmttf9N8uEk65I8fsHm5ybZJcmbW2uXrXJpAEwhY5wAmGWPS/KpJK+sqnsmOSPJ7ZIcnu4WvWdOsDYApogeJwBmVt/r9FtJ3pQuMD01yc2SvDLJHVpr50+uOgCmiR4nAGZaa+27SR456ToAmG56nAAAAAYITgAAAAMEJwAAgAGCEwAAwADBCQAAYIBZ9QBgmQ7eb/esP+GISZcBwCrQ4wQAADBAcAIAABggOAEAAAwQnAAAAAYITgAAAAMEJwAAgAGCEwAAwADBCQAAYIDgBAAAMEBwAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAdtNugAAmFLrzjjjjBx22GGTrgOAJZxxxhlJsm4cxxKcAGB5rn355Zdf/YUvfOF/Jl3IhB3YL8+caBWT5zp0XIeO69BZC9dhXZKLx3EgwQkAluf0JGmtbdVdTlW1PnEdXIeO69BxHTqzdh2McQIAABggOAEAAAyY2Vv1PrLxXTXpGgAAgNmgxwkAAGCA4AQAADCgWmuTrgEAAGBN0+MEAAAwQHACAAAYIDgBAAAMEJwAAAAGCE4AAAADBCcAAIABghMAAMAAwQkAelV1w6o6saq+V1VXVtWGqnp5VV1nxOPs2bfb0B/ne/1xb7hStY/Tll6Hqtqlqv6wqv6lqs6sqsuq6pKq+u+qempV7bDS72EcxvX9sOCYd62qq6uqVdXzx1nvShnndaiqW1XVm6vqu/2xzquqj1fVH61E7eM0xp8Pd66q9/btr6iq71TV+6vqPitV+7hU1YOq6lVVdVpVXdx/H791mcca+7+vleYBuACQpKpuluRTSfZJ8t4kZya5bZLDk5yV5E6ttfM34zh79cc5IMlHk3w+yYFJ7pfkvCR3aK19cyXewziM4zr0HwA/kOSCJKcm+UaSPZPcN8m+/fHv2Vq7YoXexhYb1/fDgmPumuTLSfZOcu0kL2itPWucdY/bOK9DVT0iyeuT/DTJ+5JsSLJHkoOTfK+19tAxlz82Y/z58Ngk/5DksiQnJTknyQ2TPCDJzkme1Vp7wUq8h3Goqi8l+c0kl6ar/cAkb2utHT3iccb+72tVtNa8vLy8vLy2+leSDyVpSZ64YP1L+/Wv2czjvLbf/6UL1h/br//gpN/rSl+HJIck+cMkOyxYv2uS9f1xnjrp97oa3w8L2p6YLkw+oz/G8yf9PlfrOiS5fZKfJ/lSkn0X2b79pN/rSl+HJNsn+UmSy5PcfMG2g5JckS5U7jjp97uJ93B4kv2TVJK79+/9rZP6vlrtlx4nALZ6VXXTJP+b7jfgN2utbZy3bdck30/3QWGf1tplmzjOLkl+lGRjkuu31i6Zt22b/hzr+nOsuV6ncV2HgXM8LMnbkryvtXbfLS56BazEdaiq+yV5T5JjkmyX5I1Z4z1O47wOVfWJJHdJcqvW2ukrVvQKGOPPh+sl+UGSL7fWfnOR7V9Ocqske7e12NuyQFXdPV2P8kg9Tqvxc2alGOMEAMk9+uWH5/8nniR9+Plkuttobj9wnDsk2SnJJ+eHpv44G5N8uP/y8C2ueGWM6zpsylX98udbcIyVNtbrUFX7JPmnJO9prS1rPMiEjOU69GP77pLkv5N8taoOr6qn9ePd7tn/UmEtG9f3w3npfrFyQFXtP39DVR2QrifnS9MQmrbQavycWRFr/RsVAFbDzfvl2Uts/3q/PGCVjjMpq1H/o/rlB7fgGCtt3Nfhdek+c/3ZlhQ1AeO6DreZt/9H+9eLkrw4ySlJvlRVv74Fda60sVyH1t3m9fh03wvrq+qfq+pvq+rN6W5h/WqSo8ZQ71o3tT8nt5t0AQCwBuzeLy9aYvvc+j1W6TiTsqL1V9UTktwn3TiXE5dzjFUytutQVY9KNzHIQ1prPxxDbatpXNdhn3754CQ/TjcRwn8muW6S56S7ffHkqrpVa+1nyy93xYzt+6G19q6q+l6Sf00yfybBH6a7fXPN3cK7Aqb256QeJwAYVv1ySwcGj+s4k7Ls+qvqAUlenm6MxwNba1cNNFnLNus6VNW6dO/5Xa21d65wTZOwud8P285bPrq1dlJr7eLW2v8meXi6W/gOSPLAlSlzxW32v4uqOjpdL9tp6SaE2Llf/meSVyd5+wrVOE3W7M9JwQkArvkN5+5LbN9twX4rfZxJWZH6q+rIdB8Iz0ty97U4McYC47oOJ6abQe1x4yhqAsZ1HS7sl1cmef/8Df3ta+/tv7ztqAWukrFch34c04npbsk7prV2Zmvt8tbamel63dYnOaqfdGGWTe3PScEJALrnhiRL31M/N5B7qXvyx32cSRl7/VV1VJJ3pbsV6W6ttbMGmqwF47oOh6a7Te1H/YNCW1W1dLdkJckz+3Xv2bJyV8y4/11csnAygN5csNpphNpW07iuw73TTUn+8UUmRdiY5BP9l4ctp8gpMrU/J41xAoBuSt0kuXdVbbPI9Lh3Stdz8JmB43ym3+9OVbXrItOR33vB+daacV2HuTYPS/LmJOcmOXwKeprmjOs6vDndrVgL7Z/krunGeq1P8sUtrnhljOs6fDnd2Ka9q+p6i4z1OrhfbtjyklfEuK7Djv3yuktsn1u/Fsd5jdNYf86sJj1OAGz1+rEWH073jKXHL9j83CS7JHnz/GeKVNWBVXXgguNcmuQt/f7HLzjOE/rjf2itBohxXYd+/cPTXYvvJLnrWn3Pixnj98OxrbVHL3zlmh6nk/t1f79ib2YLjPE6/Dzdg6GT5O/mTz9eVbdK8oh009O/e8xvYSzG+O/itH75oKr6jfkbquqQJA9KN67no+OrfnKqavv+Otxs/vrlXM+1wgNwASBJ/5/7p9LdWvXeJGckuV26Zy6dneSO85+v0t9yldZaLTjOXv1xDkj3Aehz6QZ/3y/dGJ879h8c1qRxXIeqOjzdAPht0o3p+O4ip/pJa+3lK/Q2tti4vh+WOPYjMgUPwE3G+u9i53QTINw+XQ/bx9L1sDww3S16T22tvXSF386yjfE6nJjkkel6lU5K8u10AeLIJDskeXlr7ckr/HaWrR+veGT/5b5JfifdTIBzofDHrbWn9fuuS/KtJN9ura1bcJyRrudaITgBQK+qbpTkeemmzN4r3RPs35Pkua21Cxbsu+QH5araM900y0cmuX6S85N8IMlftdbOWcn3MA5beh3mBYNN+ZUPU2vNuL4fFjnuIzIlwSkZ67+LnZP8RZKHJrlJkiuSfD7JS1prH1jJ9zAO47gOVVXpZhJ8RJLfTLJrkovThcl/aq2t6Vn1qur4dD/blvKLf9ebCk799s2+nmuF4AQAADDAGCcAAIABghMAAMAAwQkAAGCA4AQAADBAcAIAABggOAEAAAwQnAAAAAYITgAAAAMEJwAAgAGCEwAAwADBCQAAYIDgBAAAMEBwAgAAGCA4AQAADBCcAAAABghOAAAAAwQnAACAAYITAADAAMEJAABggOAEAAAwQHACAAAY8P8B4usROkOyJiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 226,
       "width": 423
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "# print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "# print(images[0,:])\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our model is the same as before: 784 input units, a hidden layer with 128 units, ReLU activation, 64 unit hidden layer, another ReLU, then the output layer with 10 units, and the softmax output.\n",
    "\n",
    "The operations are availble by passing in the appropriate index. For example, if you want to get first Linear operation and look at the weights, you'd use `model[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0176, -0.0152,  0.0208,  ...,  0.0056, -0.0165, -0.0224],\n",
       "        [ 0.0034, -0.0344,  0.0288,  ..., -0.0211, -0.0125,  0.0157],\n",
       "        [ 0.0203, -0.0226, -0.0011,  ..., -0.0301,  0.0123,  0.0172],\n",
       "        ...,\n",
       "        [-0.0092,  0.0196,  0.0161,  ...,  0.0229,  0.0143,  0.0203],\n",
       "        [ 0.0268, -0.0028,  0.0167,  ...,  0.0115, -0.0067, -0.0271],\n",
       "        [-0.0275,  0.0022,  0.0085,  ...,  0.0226, -0.0045, -0.0084]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can access layers either by integer or the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we'll see how we can train a neural network to accuractly predict the numbers appearing in the MNIST images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
